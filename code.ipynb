{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am using VS CODE. If you are using anaconda Jupyter Notebook, you might have to take care of directory navigations\n",
    "# \"\\\\\" to \"//\" \n",
    "# you can head directly to DATA EXTRACTION CELL (LAST ONE) after 5th cell. \n",
    "# Dont run cells contained in ANALYSIS OF ACQUIRED DATAETS heading. It takes time to compute and I kept them for your reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS, PATH & VARIABLE SETTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_dir = r\"output\"\n",
    "source_dir = r\"input\\April15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['Accounting Jobs.csv',\n 'Airline Jobs.csv',\n 'Analytics Jobs.csv',\n 'Application Programming Jobs.csv',\n 'Bank Jobs.csv',\n 'BPO Jobs.csv',\n 'Business Intelligence Jobs.csv',\n 'Client Server Jobs.csv',\n 'Consultant Jobs.csv',\n 'Content Writing Jobs.csv',\n 'Corporate Planning Jobs.csv',\n 'DBA Jobs.csv',\n 'Ecommerce Jobs.csv',\n 'EDP Jobs.csv',\n 'Engineering Jobs.csv',\n 'ERP Jobs.csv',\n 'Export Import Jobs.csv',\n 'Film Jobs.csv',\n 'Graphic Designer Jobs.csv',\n 'Hotel Jobs.csv',\n 'HR Jobs.csv',\n 'Interior Design Jobs.csv',\n 'IT Jobs.csv',\n 'Legal Jobs.csv',\n 'Logistics Jobs.csv',\n 'Mainframe Jobs.csv',\n 'Maintenance Jobs.csv',\n 'Marketing Jobs.csv',\n 'Merchandiser Jobs.csv',\n 'Middleware Jobs.csv',\n 'Mobile Jobs.csv',\n 'Network administrator Jobs.csv',\n 'Packaging Jobs.csv',\n 'Pharma Jobs.csv',\n 'Sales Jobs.csv',\n 'Secretary Jobs.csv',\n 'Security Jobs.csv',\n 'Shipping Jobs.csv',\n 'Site Engineering Jobs.csv',\n 'System Programming Jobs.csv',\n 'Teacher Jobs.csv',\n 'Telecom Jobs.csv',\n 'Telecom Software Jobs.csv',\n 'Testing Jobs.csv',\n 'VLSI Jobs.csv']"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "os.listdir(source_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['Record To Report-fixed Asset Accounting',\n 'Accenture Solutions Pvt Ltd',\n '4.0',\n '(14081 Reviews)',\n '1-3 Yrs',\n 'Not disclosed',\n 'Mumbai']"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df= pd.read_csv(source_dir+\"\\Accounting Jobs.csv\")\n",
    "df['header'][0].split('\\n')\n",
    "# df['footer'][1].split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS OF ACQUIRED DATAETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Header Length and no.of jobs acquired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlen=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir(source_dir):\n",
    "    curdir= source_dir+\"\\\\\"+i\n",
    "    files= os.listdir(curdir)\n",
    "    \n",
    "    for file in files:   \n",
    "        df = pd.read_csv(curdir +r\"\\\\\"+ file)\n",
    "        n = len(df)\n",
    "        #print(\"jobs scrapped=\", n)\n",
    "        for i in range(n):\n",
    "            head = df['header'][i].split('\\n')\n",
    "            headlen.append(len(head))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3, 4, 5, 6, 7}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(headlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7319221"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(headlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "footlen=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir(source_dir):\n",
    "    curdir= source_dir+\"\\\\\"+i\n",
    "    files= os.listdir(curdir)\n",
    "    \n",
    "    for file in files:\n",
    "        #print(\"extracting data from \", i, file)\n",
    "#         if os.path.exists(dest_dir+\"\\\\\"+i+file):\n",
    "#             print(file, ' exists')\n",
    "#             continue\n",
    "            \n",
    "        df = pd.read_csv(curdir +r\"\\\\\"+ file)\n",
    "        n = len(df)\n",
    "        #print(\"jobs scrapped=\", n)\n",
    "        for i in range(n):\n",
    "            foot = df['footer'][i].split('\\n')\n",
    "            footlen.append(len(foot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2, 3}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(footlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7319221"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(footlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing what features are missing for unique head length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Principal (Vacancy-1)', 'Chandigarh Institute of Hotel Management & Catering Technology (CIHM)', 'Not disclosed']\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in os.listdir(source_dir):\n",
    "    curdir= source_dir+\"\\\\\"+i\n",
    "    files= os.listdir(curdir)\n",
    "    \n",
    "    for file in files:\n",
    "        #print(\"extracting data from \", i, file)\n",
    "#         if os.path.exists(dest_dir+\"\\\\\"+i+file):\n",
    "#             print(file, ' exists')\n",
    "#             continue\n",
    "            \n",
    "        df = pd.read_csv(curdir +r\"\\\\\"+ file)\n",
    "        n = len(df)\n",
    "        #print(\"jobs scrapped=\", n)\n",
    "        for i in range(n):\n",
    "            head = df['header'][i].split('\\n')\n",
    "            headlen.append(len(head))\n",
    "            if len(head)==3: #change RHS for each unige head length\n",
    "                if count%100000 == 0 and i != 0:\n",
    "                    print(head)\n",
    "                count= count+1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Honorary Faculty - Managerial Accounting (RBL 01)', 'Rajiv Gandhi Institute of Petroleum Technology', 'Not disclosed', 'Raebareli , Raebareli']\n",
      "21861\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in os.listdir(source_dir):\n",
    "    curdir= source_dir+\"\\\\\"+i\n",
    "    files= os.listdir(curdir)\n",
    "    \n",
    "    for file in files:\n",
    "        #print(\"extracting data from \", i, file)\n",
    "#         if os.path.exists(dest_dir+\"\\\\\"+i+file):\n",
    "#             print(file, ' exists')\n",
    "#             continue\n",
    "            \n",
    "        df = pd.read_csv(curdir +r\"\\\\\"+ file)\n",
    "        n = len(df)\n",
    "        #print(\"jobs scrapped=\", n)\n",
    "        for i in range(n):\n",
    "            head = df['header'][i].split('\\n')\n",
    "            headlen.append(len(head))\n",
    "            if len(head)==4: #change RHS for each unige head length\n",
    "                if count%100000 == 0 and i != 0:\n",
    "                    print(head)\n",
    "                count= count+1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Assistant Accounting', 'DXC Technology', '1-4 Yrs', 'Not disclosed', 'Bengaluru']\n",
      "['Business Development Executive (Marketing Executive)', 'MEDICOSA', '1-4 Yrs', 'Not disclosed', 'Noida']\n",
      "['Immediate Opening For Non IT Recruiter/sourcing Specialist in MNC', 'Trigent Software Limited', '1-2 Yrs', 'Not disclosed', 'Chennai, Hyderabad']\n",
      "['Senior Student Advisor', 'Prosper Overseas Pvt Ltd', '3-7 Yrs', 'Not disclosed', 'Vijayawada']\n",
      "['Business Intelligence Analyst - Data Analysis', 'GSA Techworld', '1-4 Yrs', 'Not disclosed', 'Bengaluru']\n",
      "['Business Development Executive', 'KakInfotech', '0-2 Yrs', 'Not disclosed', 'Delhi']\n",
      "['Sr vp Sales - Internationaldales -digital Marketing -B2B', 'Naukri Premium - Employer Services', '12-20 Yrs', 'Not disclosed', 'Delhi NCR, Mumbai, Bengaluru']\n",
      "['QA Lead', 'InXero Technologies Pvt. Ltd', '3-5 Yrs', 'Not disclosed', 'Noida']\n",
      "['Manager-Accounts Payable ( SAP) in Electronic City, Bangalore', 'Osource India Private Limited', '4-9 Yrs', '3,00,000 - 5,50,000 PA.', 'Bengaluru']\n",
      "['Chief Manager - Legal - Transaction Banking - LLB', 'Pinnacle Search Services', '6-10 Yrs', 'Not disclosed', 'Mumbai']\n",
      "['Maintenance Executive', 'srsparivar', '15-18 Yrs', 'Not disclosed', 'Delhi']\n",
      "['Marketing executive', 'Besoto Starting Systems Pvt. Ltd.', '1-3 Yrs', 'Not disclosed', 'Faridabad']\n",
      "['Website Sales callers', 'ONQANET TECHNOLOGIES PVT LTD', '0-5 Yrs', 'Not disclosed', 'Kolkata']\n",
      "['Opening For Sourcing & Procurement with Ariba tool experience @ BNGLR', '2Coms Consulting Pvt Ltd.', '2-4 Yrs', '3,00,000 - 5,00,000 PA.', 'Bengaluru']\n",
      "['Manager / Senior Manager', 'Alliance Insurance Brokers Pvt. Ltd', '4-7 Yrs', 'Not disclosed', 'Chennai, Pune, Delhi, Mumbai, Bengaluru, Hyderabad']\n",
      "['Salesforce Developer', 'Tech Ringers', '6-8 Yrs', 'Not disclosed', 'Hyderabad']\n",
      "['Engineering Manager', 'Harness.io', '10-12 Yrs', 'Not disclosed', 'Bengaluru']\n",
      "['Motion Graphics Designer', 'Beard Design', '2-4 Yrs', 'Not disclosed', 'not specified']\n",
      "['PHP Developer, Kolkata, Salary 15K To 50K', 'FastInfo Legal Service Private Limited', '1-6 Yrs', '1,75,000 - 6,75,000 PA.', 'Kolkata']\n",
      "['Safety Engineer PMC Madhya Pradesh', 'Skyleaf Consultants', '5-10 Yrs', 'Not disclosed', 'Madhyapradesh Other']\n",
      "['Windows/ VMWare Administrator', 'AMBC Technologies Pvt Ltd.', '8-13 Yrs', '2,00,000 - 7,00,000 PA.', 'Hyderabad']\n",
      "['Manager', 'Seven Consultancy', '2-4 Yrs', 'Not disclosed', 'Mumbai']\n",
      "['Electronic Engineer', 'mycitypune', '4-8 Yrs', 'Not disclosed', 'Pune']\n",
      "['ACCOUNTING', 'Anvita Tours2Health Pvt. Ltd.', '2-4 Yrs', 'Not disclosed', 'Thrissur']\n",
      "['IBM BPM Consultant-5+ Years-immediate Joiner-pune or Bangalore', 'CIEL HR Services Pvt Ltd', '5-10 Yrs', '8,00,000 - 18,00,000 PA.', 'Pune, Mumbai, Bengaluru']\n",
      "['Angular JS Developer', 'Droom Technology Pvt. Ltd.', '3-8 Yrs', 'Not disclosed', 'Gurgaon']\n",
      "['Customer Support Executive', 'Santa Monica', '0-3 Yrs', 'Not disclosed', 'Kochi']\n",
      "['Opening For Android Developer Fresher', 'EndeavorITSolution', '0-1 Yrs', 'Not disclosed', 'Indore']\n",
      "['HR Recruiter', 'AXCESS CONSULTANCY SERVICES', '2-5 Yrs', 'Not disclosed', 'Ludhiana']\n",
      "['Marketing Engineer', 'mycitypune', '3-7 Yrs', 'Not disclosed', 'Pune']\n",
      "['JAVA and PHP Developer Freshers', 'EndeavorITSolution', '0-1 Yrs', 'Not disclosed', 'Indore']\n",
      "['Business Analyst with Health Care Domain', 'ITC Infotech India Ltd', '3-5 Yrs', '5,00,000 - 13,00,000 PA.', 'Bengaluru']\n",
      "['Digital Marketing Fresher', 'EndeavorITSolution', '0-0 Yrs', 'Not disclosed', 'Indore']\n",
      "['Field Sales Executive', 'Capital Placement Services', '0-3 Yrs', 'Not disclosed', 'Jammu, Bhagalpur, lakhisarai,begusarai,khagaria,balumath,khandwa,banda']\n",
      "['Admin Executive', 'Seamless Staffing', '3-6 Yrs', 'Not disclosed', 'Noida']\n",
      "['Order Fulfillment Analyst', 'Micron Technology Operations India LLP', '3-5 Yrs', 'Not disclosed', 'Hyderabad, IN, AP']\n",
      "['Big - data Technical Leads', 'VTalentGlobal', '7-12 Yrs', 'Not disclosed', 'Pune']\n",
      "['Hotel Manager (germany) - No IELTS Required', 'Dreamgateway Immigration Pvt Ltd', '0-5 Yrs', '25,00,000 - 40,00,000 PA.', 'Germany']\n",
      "['Full Stack Python Developer', 'Edge Executive Search Pvt. Ltd.', '6-10 Yrs', 'Not disclosed', 'Bengaluru(Balagere)']\n",
      "['Google Cloud Data Engineer Trainer', 'Jellyfish', '1-2 Yrs', 'Not disclosed', 'Mumbai']\n",
      "['Android Developer', 'Votive Technologies', '6-11 Yrs', 'Not disclosed', 'Indore']\n",
      "['Investment Banking Associate', 'ICS WAY', '0-2 Yrs', '1,75,000 - 3,00,000 PA.', 'Satna, Ratlam, Gwalior']\n",
      "['Internship for BBA / MBA freshers', 'EndeavorITSolution', '1-5 Yrs', 'Not disclosed', 'Indore']\n",
      "['Facets Testing - Healthcare MNC - Gurgaon/Hyderabad', 'PEOPLE STAFFING SOLUTIONS', '3-8 Yrs', '5,00,000 - 13,00,000 PA.', 'Gurgaon, Hyderabad']\n",
      "['BPO Fresher Experienced/ Collection Executive/ Salary Upto 15K/ Mumbai', 'Arise Solution', '0-5 Yrs', '1,25,000 - 2,00,000 PA.', 'Mumbai']\n",
      "['STRUCTURE ENGINEER', 'Sukhmani buildwell', '1-5 Yrs', 'Not disclosed', 'Delhi']\n",
      "['Manager/ Sr. Manager - Maintenance', 'SV Management Consultants', '10-20 Yrs', '10,00,000 - 12,00,000 PA.', 'Indore']\n",
      "['Microsave - Market - led solutions for financial services', 'MicroSave India Foundation', '3-5 Yrs', 'Not disclosed', 'Lucknow, Delhi']\n",
      "['Sales Manager , Corporate & Key Accounts FMCG Company In', 'Capital Placement Services', '5-8 Yrs', 'Not disclosed', 'Gurgaon']\n",
      "['Sales Executive', 'Cenergy MaxPowerPvt. Ltd.', '4-6 Yrs', 'Not disclosed', 'Chennai']\n",
      "4995068\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in os.listdir(source_dir):\n",
    "    curdir= source_dir+\"\\\\\"+i\n",
    "    files= os.listdir(curdir)\n",
    "    \n",
    "    for file in files:\n",
    "        #print(\"extracting data from \", i, file)\n",
    "#         if os.path.exists(dest_dir+\"\\\\\"+i+file):\n",
    "#             print(file, ' exists')\n",
    "#             continue\n",
    "            \n",
    "        df = pd.read_csv(curdir +r\"\\\\\"+ file)\n",
    "        n = len(df)\n",
    "        #print(\"jobs scrapped=\", n)\n",
    "        for i in range(n):\n",
    "            head = df['header'][i].split('\\n')\n",
    "            headlen.append(len(head))\n",
    "            if len(head)==5: #change RHS for each unige head length\n",
    "                if count%100000 == 0 and i != 0:\n",
    "                    print(head)\n",
    "                count= count+1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adjunct Faculty - Accounting', 'National Institute of Securities Markets', '4.5', '(4 Reviews)', 'Not disclosed', 'Navi Mumbai']\n",
      "70508\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in os.listdir(source_dir):\n",
    "    curdir= source_dir+\"\\\\\"+i\n",
    "    files= os.listdir(curdir)\n",
    "    \n",
    "    for file in files:\n",
    "        #print(\"extracting data from \", i, file)\n",
    "#         if os.path.exists(dest_dir+\"\\\\\"+i+file):\n",
    "#             print(file, ' exists')\n",
    "#             continue\n",
    "            \n",
    "        df = pd.read_csv(curdir +r\"\\\\\"+ file)\n",
    "        n = len(df)\n",
    "        #print(\"jobs scrapped=\", n)\n",
    "        for i in range(n):\n",
    "            head = df['header'][i].split('\\n')\n",
    "            headlen.append(len(head))\n",
    "            if len(head)==6: #change RHS for each unige head length\n",
    "                if count%100000 == 0 and i != 0:\n",
    "                    print(head)\n",
    "                count= count+1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Business Development Executive', 'Rebaca Technologies Pvt. ltd.', '3.9', '(7 Reviews)', '3-5 Yrs', '3,00,000 - 7,00,000 PA.', 'Kolkata']\n",
      "['Project Manager', 'Fluentgrid Ltd', '3.6', '(81 Reviews)', '10-15 Yrs', 'Not disclosed', 'New Delhi']\n",
      "['Financial Success Manager', 'Verizon Data Services India Pvt.Ltd', '3.6', '(527 Reviews)', '5-8 Yrs', 'Not disclosed', 'Bengaluru']\n",
      "['Front Desk Officer (fixed term Contract)', 'LUPIN LIMITED', '4.2', '(2202 Reviews)', '1-5 Yrs', 'Not disclosed', 'Indore']\n",
      "['Junior Administrator', 'SRI RAMACHANDRA HOSPITAL', '4.2', '(55 Reviews)', '3-5 Yrs', 'Not disclosed', 'Chennai']\n",
      "['Export Executive', 'Foursis Technical Solution', '4.1', '(25 Reviews)', '2-3 Yrs', 'Not disclosed', 'Ahmedabad']\n",
      "['Legal Associate / Paralegal', 'Indian Institute of Patent and Trademark', '4.2', '(36 Reviews)', '0-2 Yrs', '2,00,000 - 5,00,000 PA.', 'Pune, Bengaluru, Hyderabad']\n",
      "['DFT Engineer', 'Test and Verification Solutions India Pvt. Ltd', '4.5', '(8 Reviews)', '3-6 Yrs', 'Not disclosed', 'Bengaluru']\n",
      "['Content Analyst', 'Griha Software Technologies Pvt Ltd', '3.8', '(18 Reviews)', '1-3 Yrs', 'Not disclosed', 'Bengaluru']\n",
      "['SEARCH ENGINE OPTIMIZATION EXPERT', 'Etoile Info Solutions Pvt. Ltd.', '5.0', '(2 Reviews)', '2-4 Yrs', 'Not disclosed', 'india']\n",
      "['Specialist Development', 'Standard Chartered Bank Ltd', '4.0', '(1047 Reviews)', '2-5 Yrs', 'Not disclosed', 'Chennai']\n",
      "['Inbound Tech Support/Sales-US Shift', 'Adeeba E-Services Pvt. Ltd', '3.5', '(17 Reviews)', '1-6 Yrs', 'Not disclosed', 'Kolkata']\n",
      "['Business Development Executive', 'Nactus India Services Pvt Ltd', '5.0', '(2 Reviews)', '1-3 Yrs', 'Not disclosed', 'Itanagar, Guwahati, Dibrugarh']\n",
      "['Graphic Designer', 'Samuha Creations Ltd.', '3.8', '(4 Reviews)', '2-4 Yrs', 'Not disclosed', 'Hyderabad']\n",
      "['Front Office Executive', 'Rama Group', '3.9', '(28 Reviews)', '1-5 Yrs', 'Not disclosed', 'Pune']\n",
      "['Information Technology', 'Milliman', '3.5', '(22 Reviews)', '2-7 Yrs', 'Not disclosed', 'Gurgaon']\n",
      "['Technology Analyst', 'Infosys Technologies ltd', '3.9', '(10668 Reviews)', '3-6 Yrs', 'Not disclosed', 'Bengaluru']\n",
      "['Research Associate in Empirical Finance', 'ISB', '4.0', '(5 Reviews)', '0-4 Yrs', 'Not disclosed', 'Hyderabad']\n",
      "['Sr.team Leader- Account Receivable', 'L-Cube innovative solutions Pvt Ltd', '3.6', '(34 Reviews)', '3-5 Yrs', '5,00,000 - 6,00,000 PA.', 'Chennai(Anna Nagar West)']\n",
      "['CNC Service Engineer / Maintenance Engineer at Fanuc India', 'Fanuc India Private Limited', '3.5', '(32 Reviews)', '2-6 Yrs', 'Not disclosed', 'Pune, Ahmedabad, Manesar']\n",
      "['Delv Software Engineer', 'Mphasis Limited', '3.8', '(2290 Reviews)', '3-5 Yrs', 'Not disclosed', 'Bengaluru']\n",
      "2231771\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in os.listdir(source_dir):\n",
    "    curdir= source_dir+\"\\\\\"+i\n",
    "    files= os.listdir(curdir)\n",
    "    \n",
    "    for file in files:\n",
    "        #print(\"extracting data from \", i, file)\n",
    "#         if os.path.exists(dest_dir+\"\\\\\"+i+file):\n",
    "#             print(file, ' exists')\n",
    "#             continue\n",
    "            \n",
    "        df = pd.read_csv(curdir +r\"\\\\\"+ file)\n",
    "        n = len(df)\n",
    "        #print(\"jobs scrapped=\", n)\n",
    "        for i in range(n):\n",
    "            head = df['header'][i].split('\\n')\n",
    "            headlen.append(len(head))\n",
    "            if len(head)==7: #change RHS for each unige head length\n",
    "                if count%100000 == 0 and i != 0:\n",
    "                    print(head)\n",
    "                count= count+1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IF header_length== 3:\n",
    "    title, company, salary is recorded\n",
    "    \n",
    "### IF header_length== 4:\n",
    "    title, company, salary, location is recorded\n",
    "\n",
    "### IF header_length== 5:\n",
    "    title, company, salary, location, experience is recorded\n",
    "\n",
    "### IF header_length== 6:\n",
    "    title, company, salary, rating, reviews, location is recorded\n",
    "\n",
    "### IF header_length== 7:\n",
    "    all 7 features recorded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "extracting data from  Accounting Jobs.csv\nAccounting Jobs.csv  exists\nextracting data from  Airline Jobs.csv\nAirline Jobs.csv  exists\nextracting data from  Analytics Jobs.csv\nAnalytics Jobs.csv  exists\nextracting data from  Application Programming Jobs.csv\nApplication Programming Jobs.csv  exists\nextracting data from  Bank Jobs.csv\nBank Jobs.csv  exists\nextracting data from  BPO Jobs.csv\nBPO Jobs.csv  exists\nextracting data from  Business Intelligence Jobs.csv\nBusiness Intelligence Jobs.csv  exists\nextracting data from  Client Server Jobs.csv\nClient Server Jobs.csv  exists\nextracting data from  Consultant Jobs.csv\njobs scrapped= 40287\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e4c1a3562def>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mjob_descr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mfoot\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'footer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfoot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0mday\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mfoot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\strings.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1950\u001b[0m                 )\n\u001b[0;32m   1951\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1952\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1954\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\strings.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, pat, n, expand)\u001b[0m\n\u001b[0;32m   2623\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mforbid_nonstring_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"bytes\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2624\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2625\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2626\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturns_string\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\strings.py\u001b[0m in \u001b[0;36mstr_split\u001b[1;34m(arr, pat, n)\u001b[0m\n\u001b[0;32m   1491\u001b[0m             \u001b[0mregex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1492\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mregex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxsplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1493\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1494\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\strings.py\u001b[0m in \u001b[0;36m_na_map\u001b[1;34m(f, arr, na_result, dtype)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mna_result\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mna_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_map_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\strings.py\u001b[0m in \u001b[0;36m_map_object\u001b[1;34m(f, arr, na_mask, na_value, dtype)\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[0mconvert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[1;31m# Reraise the exception if callable `f` got wrong number of args.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer_mask\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\strings.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1485\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m                 \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1487\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1489\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time= time.time()\n",
    "files= os.listdir(source_dir)\n",
    "\n",
    "for file in files:\n",
    "    print(\"extracting data from \", file)\n",
    "    if os.path.exists(dest_dir+r\"\\\\\"+file):\n",
    "        print(file, ' exists')\n",
    "        continue\n",
    "        \n",
    "    df = pd.read_csv(source_dir +r\"\\\\\"+ file)\n",
    "    n = len(df)\n",
    "    print(\"jobs scrapped=\", n)\n",
    "    \n",
    "    areas=[]\n",
    "    titles = []\n",
    "    companies = []\n",
    "    ratings = []\n",
    "    reviews = []\n",
    "    experiences = []\n",
    "    salaries = []\n",
    "    locations = []\n",
    "    descriptions = []\n",
    "    naukri_categories = []\n",
    "    posted_days = []\n",
    "    tags = []\n",
    "\n",
    "    if 'tags' in df.columns:\n",
    "        for i in range(n):\n",
    "            tag= df['tags'].str.split('\\n')\n",
    "            tag= ','.join(tag)\n",
    "\n",
    "            tags.append(tag)\n",
    "\n",
    "    df['footer']= df['footer'].replace('\\nSave', '', regex=True)\n",
    "    \n",
    "    #this is where the task is taking too much time to run\n",
    "    for i in range(n):\n",
    "        \n",
    "        head = df['header'][i].split('\\n')\n",
    "        if len(head)==7:\n",
    "            title= head[0]\n",
    "            company= head[1]\n",
    "            rating= head[2]\n",
    "            review= head[3]\n",
    "            experience= head[4]\n",
    "            salary= head[5]\n",
    "            location= head[6]\n",
    "        elif len(head)==5:\n",
    "            title= head[0]\n",
    "            company= head[1]\n",
    "            rating= np.nan\n",
    "            review= np.nan\n",
    "            experience= head[2]\n",
    "            salary= head[3]\n",
    "            location= head[4]\n",
    "        elif len(head)==6:\n",
    "            title= head[0]\n",
    "            company= head[1]\n",
    "            rating= head[2]\n",
    "            review= head[3]\n",
    "            experience= np.nan\n",
    "            salary= head[4]\n",
    "            location= head[5]\n",
    "        elif len(head)==4:\n",
    "            title= head[0]\n",
    "            company= head[1]\n",
    "            rating= np.nan\n",
    "            review= np.nan\n",
    "            experience= np.nan\n",
    "            salary= head[2]\n",
    "            location= head[3]\n",
    "        else:\n",
    "            title= head[0]\n",
    "            company= head[1]\n",
    "            rating= np.nan\n",
    "            review= np.nan\n",
    "            experience= np.nan\n",
    "            salary= head[2]\n",
    "            location= np.nan\n",
    "        \n",
    "        job_descr = df['description'][i]\n",
    "\n",
    "        foot= df['footer'].str.split('\\n')\n",
    "        if len(foot[i])==2:\n",
    "            day= foot[i][1]\n",
    "            category= foot[i][0]\n",
    "        else:\n",
    "            day= foot[i][0]\n",
    "            category= np.nan\n",
    "\n",
    "        areas.append(str(file[:-9]))\n",
    "        titles.append(title)\n",
    "        companies.append(company)\n",
    "        ratings.append(rating)\n",
    "        reviews.append(review)\n",
    "        experiences.append(experience)\n",
    "        salaries.append(salary)\n",
    "        locations.append(location)\n",
    "        descriptions.append(job_descr)\n",
    "        posted_days.append(day)\n",
    "        naukri_categories.append(category)\n",
    "\n",
    "        if i%10000 == 0 and i != 0:\n",
    "            print('\\t', i, n)\n",
    "    #till here..... THIS CHUNK NEEDS TO BE OPTIMIZED\n",
    "    \n",
    "    df1 = pd.DataFrame()\n",
    "    df1['functional area']=areas\n",
    "    df1['title']=titles\n",
    "    df1['company']=companies\n",
    "    df1['experience']=experiences\n",
    "    df1['salary']=salaries\n",
    "    df1['location']=locations\n",
    "    df1['description']=descriptions\n",
    "    df1['naukri categories']= naukri_categories\n",
    "    df1['posted_days']=posted_days\n",
    "    df1['scraped_on']=df['scraped_time']\n",
    "    df1['rating']=ratings\n",
    "    df1['review']=reviews\n",
    "    if len(tags)!=0:\n",
    "        df1['tags']= tags\n",
    "    print('Extraction completed, writing to destination ', file)\n",
    "    df1.to_csv(dest_dir+r\"\\\\\"+file, index=False)\n",
    "    \n",
    "    print(\"time_taken for file=\", (start_time-time.time())/60, \" minutes\")\n",
    "print(\"time_taken for folder=\", (start_time-time.time())/60, \" minutes\")\n",
    "print(\"time_taken for all data acroos all folders=\", (start_time-time.time())/60, \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probale solution I think that will work but I am unable to convert it to code because I am not good at groupby and collating results on pandas group computation to end results file\n",
    "\n",
    "# df.groupby(header length after split)\n",
    "# perform computation for each group\n",
    "\n",
    "# this way instead of each row processed at a time, each gr0up will be processed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}